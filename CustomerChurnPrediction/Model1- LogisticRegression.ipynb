{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will classify the list of customers based on whether a customer will churn or not.In this data, false negative costs higher. If the customer is churned, but if we faslely predicted them as 'will not churn' then it costs higher.\n",
    "We do not want to lose the customer by falsely identifying them as non-churning customer. So we will give more importance to recall compared to accuracy, precision and other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data\\PreprocessedBankChurners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, df.columns != 'Attrition_Flag']\n",
    "y = df['Attrition_Flag']\n",
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.25, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression( )\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test) \n",
    "#(solvers=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2062   48]\n",
      " [ 221  201]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      2110\n",
      "           1       0.81      0.48      0.60       422\n",
      "\n",
      "    accuracy                           0.89      2532\n",
      "   macro avg       0.86      0.73      0.77      2532\n",
      "weighted avg       0.89      0.89      0.88      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though accuracy is good, we need precision here. This is low for Attrited customer(48%)\n",
    "So, we need to improve the model.\n",
    "As there are many skewed data, since we get better results after standardization, we will standardize for Logistic Regression and tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, df.columns != 'Attrition_Flag']\n",
    "y = df['Attrition_Flag']\n",
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': Cs}\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned parameter value = {'C': 10}\n",
      "Best score = 0.9049374588545096\n"
     ]
    }
   ],
   "source": [
    "logreg_cv.fit(X_train_scaled, y_train)\n",
    "print(\"Tuned parameter value = {}\". format(logreg_cv.best_params_))\n",
    "print('Best score = {}'. format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best value for C is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      2113\n",
      "           1       0.76      0.56      0.65       419\n",
      "\n",
      "    accuracy                           0.90      2532\n",
      "   macro avg       0.84      0.76      0.79      2532\n",
      "weighted avg       0.89      0.90      0.89      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_best_param = LogisticRegression(C=10)\n",
    "logreg_best_param.fit(X_train_scaled, y_train)\n",
    "y_pred = logreg_best_param.predict(X_test_scaled) \n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall has increased from 48% to 56% but still is very low. So we will try other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
